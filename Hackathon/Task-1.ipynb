{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data = pd.read_csv('./train.csv')\n",
        "train_data = train_data.drop([\"Cabin\", \"PassengerId\", \"Name\", \"Ticket\"], axis=1)\n",
        "test_data = pd.read_csv('./test.csv')\n",
        "test_data = test_data.drop([\"Cabin\", \"PassengerId\", \"Name\", \"Ticket\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data = train_data.dropna()\n",
        "test_data = test_data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
              "0         0       3    male  22.0      1      0   7.2500        S\n",
              "1         1       1  female  38.0      1      0  71.2833        C\n",
              "2         1       3  female  26.0      0      0   7.9250        S\n",
              "3         1       1  female  35.0      1      0  53.1000        S\n",
              "4         0       3    male  35.0      0      0   8.0500        S"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.head()\n",
        "# train_data.describe()\n",
        "# print(test_data)\n",
        "# print(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "embarked_mapping = {embarked: i for i, embarked in enumerate(train_data['Embarked'].unique())}\n",
        "gender_mapping = {sex: i for i, sex in enumerate(train_data['Sex'].unique())}\n",
        "\n",
        "embarked_mapping.update({embarked: i for i, embarked in enumerate(test_data['Embarked'].unique())})\n",
        "gender_mapping.update({sex: i for i, sex in enumerate(test_data['Sex'].unique())})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Encode categorical variables\n",
        "train_data['Embarked'] = train_data['Embarked'].map(embarked_mapping)\n",
        "train_data['Sex'] = train_data['Sex'].map(gender_mapping)\n",
        "\n",
        "test_data['Embarked'] = test_data['Embarked'].map(embarked_mapping)\n",
        "test_data['Sex'] = test_data['Sex'].map(gender_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "selected_features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data[selected_features] = (train_data[selected_features] - train_data[selected_features].mean()) / train_data[selected_features].std()\n",
        "test_data = (test_data - test_data.mean()) / test_data.std()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = train_data.drop('Survived', axis=1).values\n",
        "y_train = train_data['Survived'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(len(selected_features), 50)\n",
        "        self.fc2 = nn.Linear(50, 1)\n",
        "        self.fc3 = nn.Linear(1, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.sigmoid(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, X_train, y_train, epochs=1000):\n",
        "    X_train = torch.Tensor(X_train)\n",
        "    y_train = torch.Tensor(y_train)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_train)\n",
        "        loss = criterion(outputs, y_train.float().unsqueeze(1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = NeuralNetwork()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/1000], Loss: 0.6085190176963806\n",
            "Epoch [20/1000], Loss: 0.5236503481864929\n",
            "Epoch [30/1000], Loss: 0.46910974383354187\n",
            "Epoch [40/1000], Loss: 0.44890153408050537\n",
            "Epoch [50/1000], Loss: 0.4456418454647064\n",
            "Epoch [60/1000], Loss: 0.4414485991001129\n",
            "Epoch [70/1000], Loss: 0.4389791488647461\n",
            "Epoch [80/1000], Loss: 0.43631166219711304\n",
            "Epoch [90/1000], Loss: 0.43330204486846924\n",
            "Epoch [100/1000], Loss: 0.42985770106315613\n",
            "Epoch [110/1000], Loss: 0.42593929171562195\n",
            "Epoch [120/1000], Loss: 0.4215456545352936\n",
            "Epoch [130/1000], Loss: 0.41671809554100037\n",
            "Epoch [140/1000], Loss: 0.4114323854446411\n",
            "Epoch [150/1000], Loss: 0.4056311547756195\n",
            "Epoch [160/1000], Loss: 0.399372398853302\n",
            "Epoch [170/1000], Loss: 0.39285808801651\n",
            "Epoch [180/1000], Loss: 0.3862791061401367\n",
            "Epoch [190/1000], Loss: 0.3798447847366333\n",
            "Epoch [200/1000], Loss: 0.37367093563079834\n",
            "Epoch [210/1000], Loss: 0.367669016122818\n",
            "Epoch [220/1000], Loss: 0.3617028594017029\n",
            "Epoch [230/1000], Loss: 0.3558383584022522\n",
            "Epoch [240/1000], Loss: 0.3502811789512634\n",
            "Epoch [250/1000], Loss: 0.3451354503631592\n",
            "Epoch [260/1000], Loss: 0.3403645157814026\n",
            "Epoch [270/1000], Loss: 0.3357064425945282\n",
            "Epoch [280/1000], Loss: 0.33123794198036194\n",
            "Epoch [290/1000], Loss: 0.32692211866378784\n",
            "Epoch [300/1000], Loss: 0.32286831736564636\n",
            "Epoch [310/1000], Loss: 0.31902945041656494\n",
            "Epoch [320/1000], Loss: 0.31532588601112366\n",
            "Epoch [330/1000], Loss: 0.31171566247940063\n",
            "Epoch [340/1000], Loss: 0.30813032388687134\n",
            "Epoch [350/1000], Loss: 0.30448856949806213\n",
            "Epoch [360/1000], Loss: 0.30073535442352295\n",
            "Epoch [370/1000], Loss: 0.2968890070915222\n",
            "Epoch [380/1000], Loss: 0.29301533102989197\n",
            "Epoch [390/1000], Loss: 0.2891477048397064\n",
            "Epoch [400/1000], Loss: 0.2852656841278076\n",
            "Epoch [410/1000], Loss: 0.2815456688404083\n",
            "Epoch [420/1000], Loss: 0.2776009738445282\n",
            "Epoch [430/1000], Loss: 0.2735998332500458\n",
            "Epoch [440/1000], Loss: 0.26954275369644165\n",
            "Epoch [450/1000], Loss: 0.26534852385520935\n",
            "Epoch [460/1000], Loss: 0.2610792815685272\n",
            "Epoch [470/1000], Loss: 0.2568373382091522\n",
            "Epoch [480/1000], Loss: 0.25319936871528625\n",
            "Epoch [490/1000], Loss: 0.2492711991071701\n",
            "Epoch [500/1000], Loss: 0.24603404104709625\n",
            "Epoch [510/1000], Loss: 0.24282725155353546\n",
            "Epoch [520/1000], Loss: 0.2397407740354538\n",
            "Epoch [530/1000], Loss: 0.2367515116930008\n",
            "Epoch [540/1000], Loss: 0.23384031653404236\n",
            "Epoch [550/1000], Loss: 0.23123955726623535\n",
            "Epoch [560/1000], Loss: 0.22852067649364471\n",
            "Epoch [570/1000], Loss: 0.22612479329109192\n",
            "Epoch [580/1000], Loss: 0.22372479736804962\n",
            "Epoch [590/1000], Loss: 0.22137421369552612\n",
            "Epoch [600/1000], Loss: 0.21905416250228882\n",
            "Epoch [610/1000], Loss: 0.21680361032485962\n",
            "Epoch [620/1000], Loss: 0.21455025672912598\n",
            "Epoch [630/1000], Loss: 0.21247805655002594\n",
            "Epoch [640/1000], Loss: 0.21044977009296417\n",
            "Epoch [650/1000], Loss: 0.2084645926952362\n",
            "Epoch [660/1000], Loss: 0.20647196471691132\n",
            "Epoch [670/1000], Loss: 0.20450729131698608\n",
            "Epoch [680/1000], Loss: 0.20275987684726715\n",
            "Epoch [690/1000], Loss: 0.20086751878261566\n",
            "Epoch [700/1000], Loss: 0.19921304285526276\n",
            "Epoch [710/1000], Loss: 0.19740496575832367\n",
            "Epoch [720/1000], Loss: 0.1957985907793045\n",
            "Epoch [730/1000], Loss: 0.1943521350622177\n",
            "Epoch [740/1000], Loss: 0.19279378652572632\n",
            "Epoch [750/1000], Loss: 0.19131328165531158\n",
            "Epoch [760/1000], Loss: 0.1899217814207077\n",
            "Epoch [770/1000], Loss: 0.18854229152202606\n",
            "Epoch [780/1000], Loss: 0.18717515468597412\n",
            "Epoch [790/1000], Loss: 0.18729884922504425\n",
            "Epoch [800/1000], Loss: 0.18495242297649384\n",
            "Epoch [810/1000], Loss: 0.1838962435722351\n",
            "Epoch [820/1000], Loss: 0.18239545822143555\n",
            "Epoch [830/1000], Loss: 0.18132561445236206\n",
            "Epoch [840/1000], Loss: 0.180192768573761\n",
            "Epoch [850/1000], Loss: 0.17907796800136566\n",
            "Epoch [860/1000], Loss: 0.17797186970710754\n",
            "Epoch [870/1000], Loss: 0.17687448859214783\n",
            "Epoch [880/1000], Loss: 0.17577607929706573\n",
            "Epoch [890/1000], Loss: 0.17467646300792694\n",
            "Epoch [900/1000], Loss: 0.17359499633312225\n",
            "Epoch [910/1000], Loss: 0.1726662814617157\n",
            "Epoch [920/1000], Loss: 0.1730891615152359\n",
            "Epoch [930/1000], Loss: 0.17104755342006683\n",
            "Epoch [940/1000], Loss: 0.16981825232505798\n",
            "Epoch [950/1000], Loss: 0.16883504390716553\n",
            "Epoch [960/1000], Loss: 0.16794095933437347\n",
            "Epoch [970/1000], Loss: 0.16700699925422668\n",
            "Epoch [980/1000], Loss: 0.16609564423561096\n",
            "Epoch [990/1000], Loss: 0.1651863157749176\n",
            "Epoch [1000/1000], Loss: 0.16427959501743317\n"
          ]
        }
      ],
      "source": [
        "train_model(model, criterion, optimizer, X_train, y_train, epochs=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.10604007e-04 1.91147009e-08 3.67513451e-08 1.71365380e-01\n",
            " 1.68203442e-08 4.04275239e-01 1.41737640e-01 6.09164520e-13\n",
            " 3.96305621e-01 5.32182111e-12 3.13457608e-01 1.00000000e+00\n",
            " 2.49257596e-07 1.00000000e+00 1.00000000e+00 4.59492876e-04\n",
            " 9.34079468e-01 2.68262182e-03 3.06272305e-08 2.37671398e-02\n",
            " 9.99879241e-01 9.99998569e-01 9.99984384e-01 5.07976150e-09\n",
            " 1.00000000e+00 9.55528557e-01 5.24325967e-01 2.01915941e-06\n",
            " 2.28007464e-03 1.66060213e-13 7.14972317e-01 4.84450758e-01\n",
            " 6.72997057e-01 8.82547796e-02 9.68492532e-05 1.53020501e-01\n",
            " 9.99166012e-01 1.00000000e+00 1.48511291e-01 8.09482634e-01\n",
            " 9.99990821e-01 3.02770699e-04 8.54749791e-03 2.58608583e-08\n",
            " 8.51682425e-01 9.99998689e-01 2.80261803e-11 1.53856194e-02\n",
            " 1.61711350e-01 1.00000000e+00 1.76193550e-01 2.82117039e-01\n",
            " 1.39689863e-01 3.11753362e-01 9.85376346e-07 4.75588769e-01\n",
            " 1.68773700e-02 5.56654530e-03 2.20275178e-05 1.95700690e-01\n",
            " 9.51359868e-02 6.54845715e-01 3.86608328e-04 1.00000000e+00\n",
            " 9.00565982e-01 1.00000000e+00 6.32958859e-02 1.95700690e-01\n",
            " 2.88221762e-02 9.99869108e-01 5.05104423e-01 1.33095428e-01\n",
            " 6.44242406e-01 9.99999404e-01 1.79287285e-01 1.00000000e+00\n",
            " 1.49591584e-02 1.54610381e-01 9.99999642e-01 2.71483094e-01\n",
            " 7.56557405e-01 9.14176255e-02 1.00000000e+00 3.21477256e-03\n",
            " 1.86515212e-01 9.37444791e-02 1.06120016e-02 2.21295878e-02\n",
            " 5.10653257e-02 2.37564916e-11 1.00000000e+00 4.13372219e-01\n",
            " 1.00000000e+00 1.00000000e+00 9.85664368e-01 2.28135887e-05\n",
            " 4.17023450e-02 9.99985456e-01 1.00000000e+00 2.82698721e-01\n",
            " 9.35336530e-01 9.84091237e-02 2.80260563e-01 1.17076248e-01\n",
            " 1.87304348e-01 8.30893870e-03 2.56096780e-01 1.24969564e-01\n",
            " 9.62398410e-01 2.05648760e-03 5.64526975e-01 8.45690817e-02\n",
            " 9.15593565e-01 1.00000000e+00 2.30511123e-05 1.32957837e-02\n",
            " 4.32852566e-01 4.92563457e-09 9.00098309e-02 1.52451328e-14\n",
            " 1.00000000e+00 2.27034281e-04 1.96098270e-07 1.38032526e-01\n",
            " 1.00000000e+00 5.73077500e-01 4.32852566e-01 9.72923636e-01\n",
            " 2.49866070e-03 7.37139642e-01 2.23209605e-01 2.30838388e-08\n",
            " 9.34317172e-01 1.11138682e-10 5.83606005e-01 9.58550274e-01\n",
            " 3.20043676e-02 1.45831038e-07 1.00000000e+00 9.99998569e-01\n",
            " 1.55518148e-02 9.98625755e-01 9.99999285e-01 6.32958859e-02\n",
            " 2.30886813e-04 1.00000000e+00 1.00000000e+00 1.29935429e-01\n",
            " 9.99999404e-01 1.84053358e-12 1.55553848e-01 4.81793396e-02\n",
            " 9.96949732e-01 9.89968107e-09 9.99999762e-01 9.35210064e-02\n",
            " 1.00000000e+00 6.63194418e-01 3.63235176e-02 1.00000000e+00\n",
            " 9.99999404e-01 1.00000000e+00 2.66995188e-03 4.94462717e-03\n",
            " 8.69980920e-03 1.00000000e+00 1.49873748e-01 9.50396881e-02\n",
            " 9.38046196e-10 1.66688376e-04 1.00000000e+00 5.35720363e-02\n",
            " 1.00000000e+00 1.00000000e+00 9.99997616e-01 9.02361423e-02\n",
            " 5.09739459e-01 9.84242484e-02 6.70874834e-01 1.07846722e-01\n",
            " 9.24261510e-02 8.12749788e-02 4.37370890e-10 1.00000000e+00\n",
            " 1.41194597e-01 9.96506751e-01 1.03297316e-01 4.27027494e-02\n",
            " 8.69495571e-01 9.99999642e-01 1.00000000e+00 9.38740134e-01\n",
            " 9.99999881e-01 1.31512599e-04 9.65630829e-01 9.57987726e-01\n",
            " 1.37389600e-10 4.17023450e-02 1.00000000e+00 1.01018384e-01\n",
            " 2.20966118e-04 7.49612972e-02 1.14524521e-01 2.34393507e-01\n",
            " 9.98380661e-01 9.91190597e-02 1.40326748e-07 9.64936540e-02\n",
            " 9.99999046e-01 9.95379567e-01 1.18430286e-07 1.57217607e-01\n",
            " 6.79985678e-05 1.00000000e+00 9.99378920e-01 4.92429966e-03\n",
            " 1.35919745e-05 7.07932860e-02 1.13859847e-01 5.37121177e-01\n",
            " 1.00000000e+00 4.59446572e-03 9.72745180e-01 1.14104887e-02\n",
            " 4.11658630e-06 1.50245562e-01 6.51764683e-03 1.05286688e-02\n",
            " 1.80122405e-01 1.00000000e+00 8.17301273e-02 2.75568306e-01\n",
            " 1.94717184e-01 4.80877759e-07 9.49051082e-02 1.00000000e+00\n",
            " 9.99211907e-01 9.97519672e-01 2.91826262e-04 3.40518454e-06\n",
            " 1.14567794e-01 9.52413023e-01 3.84586351e-03 1.00000000e+00\n",
            " 5.74607193e-01 7.63208747e-01 1.12749197e-01 2.13797212e-01\n",
            " 6.14062708e-04 1.86515212e-01 9.62134480e-01 2.05648760e-03\n",
            " 9.47698176e-01 1.00000000e+00 1.38276607e-01 9.93366063e-01\n",
            " 5.41258350e-06 6.84780329e-02 1.60600528e-01 9.99998808e-01\n",
            " 4.59157944e-01 6.63157463e-01 2.11449131e-01 3.97271574e-01\n",
            " 2.77967423e-01 1.07816023e-08 2.67386297e-03 4.96765748e-02\n",
            " 2.00177595e-01 1.00000000e+00 2.45970771e-01 2.05648760e-03\n",
            " 2.32463979e-11 1.16807828e-02 9.99346197e-01 9.99998689e-01\n",
            " 2.66995188e-03 4.55750687e-10 2.38775351e-06 9.98767138e-01\n",
            " 5.54031849e-01 1.00000000e+00 5.20365546e-03 8.14860046e-01\n",
            " 1.00000000e+00 9.99346197e-01 1.71365380e-01 1.00000000e+00\n",
            " 2.37456174e-03 9.99998212e-01 7.49748779e-08 4.95087932e-07\n",
            " 1.00000000e+00 1.11009814e-02 2.26380378e-01 1.00000000e+00\n",
            " 1.00000000e+00 1.48185052e-06 1.82556912e-01 2.43026375e-06\n",
            " 1.32751360e-04 9.31970537e-01 4.27357927e-02 9.95501459e-01\n",
            " 1.28276065e-01 1.63651466e-01 2.27181185e-02 7.40069325e-11\n",
            " 4.60297088e-06 9.99996424e-01 9.98356044e-01 4.46030833e-02\n",
            " 1.43239100e-04 1.00000000e+00 5.35004020e-01 1.00000000e+00\n",
            " 9.91231129e-02 7.75121689e-01 1.00000000e+00 1.24828570e-04\n",
            " 1.00000000e+00 1.96778983e-01 2.24515243e-04 2.53627036e-07\n",
            " 1.98820976e-06 9.56468880e-01 9.91315067e-01 9.99999762e-01\n",
            " 6.88079715e-01 1.00000000e+00 3.41147929e-02]\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    X_test_tensor = torch.from_numpy(test_data.values).float()\n",
        "    outputs = torch.sigmoid(model(X_test_tensor)).squeeze().numpy()\n",
        "\n",
        "print(outputs)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
